{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f0b7d7",
   "metadata": {},
   "source": [
    "# üçè Observability & Tracing Demo with `azure-ai-projects` and `azure-ai-inference` üçé\n",
    "\n",
    "> üìö **For developers and learners**: Refer to the official Azure AI Foundry observability documentation: [https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/observability](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/observability)\n",
    "\n",
    "Welcome to this **Health & Fitness**-themed notebook, where we'll explore how to set up **observability** and **tracing** for:\n",
    "\n",
    "1. **Basic LLM calls** using an `AIProjectClient`.\n",
    "2. **Multi-step** interactions using an **Agent** (such as a Health Resource Agent).\n",
    "3. **Tracing** your local usage in **console** (stdout) or via an **OTLP endpoint** (like **Prompty** or **Aspire**).\n",
    "4. Sending those **traces** to **Azure Monitor** (Application Insights) so you can view them in **Azure AI Foundry**.\n",
    "\n",
    "> **Disclaimer**: This is a fun demonstration of AI and observability! Any references to workouts, diets, or health routines in the code or prompts are purely for **educational** purposes. Always consult a professional for health advice.\n",
    "\n",
    "## Contents\n",
    "1. **Initialization**: Setting up environment, creating clients.\n",
    "2. **Basic LLM Call**: Quick demonstration of retrieving model completions.\n",
    "3. **Connections**: Listing project connections.\n",
    "4. **Observability & Tracing**\n",
    "   - **Azure Monitor** tracing: hooking up to Application Insights\n",
    "   - **Verifying** your traces in Azure AI Foundry\n",
    "5. **Agent-based Example**:\n",
    "   - Creating a simple \"Health Resource Agent\" referencing sample docs.\n",
    "   - Multi-turn conversation with tracing.\n",
    "   - Cleanup.\n",
    "\n",
    "<img src=\"./seq-diagrams/1-observability.png\" width=\"75%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d687ae",
   "metadata": {},
   "source": [
    "## üîê Authentication Setup\n",
    "\n",
    "Before running the next cell, make sure you're authenticated with Azure CLI. Run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "az login --use-device-code\n",
    "```\n",
    "\n",
    "This will provide you with a device code and URL to authenticate in your browser, which is useful for:\n",
    "- Remote development environments\n",
    "- Systems without a default browser\n",
    "- Corporate environments with strict security policies\n",
    "\n",
    "After successful authentication, you can proceed with the notebook cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13f9f3",
   "metadata": {},
   "source": [
    "## 1. Initialization & Setup\n",
    "**Prerequisites**:\n",
    "- A `.env` file containing `AI_FOUNDRY_PROJECT_ENDPOINT` (and optionally `MODEL_DEPLOYMENT_NAME`).\n",
    "- Roles/permissions in Azure AI Foundry that let you do inference & agent creation.\n",
    "- A local environment with `azure-ai-projects`, `azure-ai-inference`, `opentelemetry` packages installed.\n",
    "\n",
    "**What we do**:\n",
    "- Load environment variables.\n",
    "- Initialize `AIProjectClient`.\n",
    "- Check that we can talk to a model (like `gpt-4o`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ccdace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.inference.models import UserMessage, CompletionsFinishReason\n",
    "\n",
    "# Load environment variables\n",
    "notebook_path = Path().absolute()\n",
    "env_path = notebook_path.parent.parent / '.env'  # Adjust path as needed\n",
    "load_dotenv(env_path)\n",
    "\n",
    "project_endpoint = os.environ.get(\"AI_FOUNDRY_PROJECT_ENDPOINT\")\n",
    "tenant_id = os.environ.get(\"TENANT_ID\")\n",
    "if not project_endpoint:\n",
    "    raise ValueError(\"üö® AI_FOUNDRY_PROJECT_ENDPOINT not set in .env.\")\n",
    "\n",
    "print(f\"üîë Using Tenant ID: {tenant_id}\")\n",
    "\n",
    "# Initialize AIProjectClient with simplified browser-based authentication\n",
    "try:\n",
    "    print(\"üåê Using browser-based authentication to bypass Azure CLI cache issues...\")\n",
    "    \n",
    "    # Use only InteractiveBrowserCredential with the specific tenant\n",
    "    credential = InteractiveBrowserCredential(tenant_id=tenant_id)\n",
    "    \n",
    "    # Create the project client using endpoint\n",
    "    project_client = AIProjectClient(\n",
    "        endpoint=project_endpoint,\n",
    "        credential=credential\n",
    "    )\n",
    "    print(\"‚úÖ Successfully created AIProjectClient!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating AIProjectClient: {e}\")\n",
    "    print(\"üí° Please complete the browser authentication prompt that should appear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24461b",
   "metadata": {},
   "source": [
    "## 2. Basic LLM Call\n",
    "We'll do a **quick** chat completion request to confirm everything is working. We'll ask a simple question: \"How many feet are in a mile?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcdaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "try:\n",
    "    # Use the correct Azure AI Projects SDK pattern\n",
    "    print(\"üîÑ Getting OpenAI client from Azure AI Project...\")\n",
    "    print(f\"ü§ñ Using model: {model_deployment_name}\")\n",
    "    \n",
    "    # Get OpenAI client using the correct method\n",
    "    openai_client = project_client.get_openai_client(api_version=\"2024-10-21\")\n",
    "    \n",
    "    # Create chat completion using OpenAI client pattern\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model_deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful health assistant\"},\n",
    "            {\"role\": \"user\", \"content\": \"How to be healthy in one sentence?\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Successfully created chat completion!\")\n",
    "    print(f\"ü§ñ Assistant: {response.choices[0].message.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå An error occurred: {str(e)}\")\n",
    "    print(\"üí° Troubleshooting tips:\")\n",
    "    print(\"  - Ensure your Azure AI Project has OpenAI connections configured\")\n",
    "    print(\"  - Verify your MODEL_DEPLOYMENT_NAME is correctly deployed\")\n",
    "    print(\"  - Check that you have proper permissions to access the model\")\n",
    "    print(\"  - Make sure you're using the latest azure-ai-projects SDK version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce0c8f7",
   "metadata": {},
   "source": [
    "## 3. Observability & Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d366bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install packages exactly as specified in Microsoft documentation if not installed using requirements.txt\n",
    "# !pip install azure-ai-projects azure-monitor-opentelemetry opentelemetry-instrumentation-openai-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767143a",
   "metadata": {},
   "source": [
    "## 3.1 Set Environment Variables for Content Capture\n",
    "\n",
    "According to Microsoft documentation, we need to set the environment variable `AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED` to capture message content (prompts and responses). This should be set **before** any instrumentation.\n",
    "\n",
    "**Important**: This may contain personal data, so use with caution in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef06776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variable to enable content recording BEFORE instrumentation\n",
    "# This follows the official Microsoft documentation pattern\n",
    "print(\"üîß Setting up environment variables for tracing...\")\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n",
    "print(\"‚úÖ Content recording enabled for traces (prompts and responses will be captured)\")\n",
    "print(\"‚ö†Ô∏è  Note: This may contain personal data - use with caution in production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480fbc30",
   "metadata": {},
   "source": [
    "## 3.2 Configure Azure Monitor Tracing\n",
    "\n",
    "Following the official Microsoft documentation, we will:\n",
    "1. Get the Application Insights connection string from the project\n",
    "2. Configure Azure Monitor using `configure_azure_monitor()`\n",
    "3. Instrument the OpenAI SDK using `OpenAIInstrumentor()`\n",
    "\n",
    "This setup ensures all traces are sent to Azure AI Foundry's Tracing tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry.instrumentation.openai_v2 import OpenAIInstrumentor\n",
    "\n",
    "print(\"üîß Setting up Azure Monitor tracing for AI Foundry...\")\n",
    "\n",
    "try:\n",
    "    # Step 1: Get the Application Insights connection string from the project\n",
    "    connection_string = project_client.telemetry.get_application_insights_connection_string()\n",
    "    \n",
    "    if connection_string:\n",
    "        print(\"‚úÖ Retrieved Application Insights connection string\")\n",
    "        \n",
    "        # Step 2: Configure Azure Monitor with the connection string (Microsoft official pattern)\n",
    "        configure_azure_monitor(connection_string=connection_string)\n",
    "        print(\"‚úÖ Azure Monitor configured successfully\")\n",
    "        \n",
    "        # Step 3: Instrument the OpenAI SDK (Microsoft official pattern)\n",
    "        OpenAIInstrumentor().instrument()\n",
    "        print(\"‚úÖ OpenAI SDK instrumented for tracing\")\n",
    "        \n",
    "        print(\"\\nüéØ Tracing is now active! All API calls will be sent to Azure AI Foundry.\")\n",
    "        print(\"üìä View traces at: https://ai.azure.com -> Your Project -> Tracing\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No Application Insights connection string found\")\n",
    "        print(\"üí° Please ensure your AI Foundry project has Application Insights connected\")\n",
    "        print(\"   Go to: Azure AI Foundry Portal -> Your Project -> Tracing -> Enable tracing\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to configure Azure Monitor: {e}\")\n",
    "    print(\"üí° Troubleshooting:\")\n",
    "    print(\"   1. Ensure Application Insights is connected to your AI Foundry project\")\n",
    "    print(\"   2. Check you have proper permissions (Contributor role)\")\n",
    "    print(\"   3. Verify the project endpoint is correct in your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0fdd4",
   "metadata": {},
   "source": [
    "## 3.3 Test Basic Tracing with OpenAI Call\n",
    "\n",
    "Now let's make a simple OpenAI call to verify that tracing is working. This trace should appear in the Azure AI Foundry Tracing tab within a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a simple OpenAI call to test tracing\n",
    "print(\"üß™ Testing tracing with a simple OpenAI call...\")\n",
    "\n",
    "try:\n",
    "    client = project_client.get_openai_client(api_version=\"2024-10-21\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Write a short poem on open telemetry.\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ OpenAI call completed successfully!\")\n",
    "    print(f\"\\nü§ñ Response:\\n{response.choices[0].message.content}\\n\")\n",
    "    print(\"üîç This interaction should now be visible in Azure AI Foundry Tracing tab\")\n",
    "    print(\"‚è±Ô∏è  Note: Traces may take 2-5 minutes to appear in the portal\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during test call: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2d871",
   "metadata": {},
   "source": [
    "## 3.4 Optional: Console Tracing for Local Debugging\n",
    "\n",
    "If you want to see traces in your local console output (useful for debugging), you can set up a console exporter. This is in addition to Azure Monitor tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set up console tracing for local debugging\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "\n",
    "print(\"üîß Setting up console tracing for local debugging...\")\n",
    "\n",
    "try:\n",
    "    # Get the current tracer provider (already configured by Azure Monitor)\n",
    "    tracer_provider = trace.get_tracer_provider()\n",
    "    \n",
    "    # Add console exporter to see traces in stdout\n",
    "    console_exporter = ConsoleSpanExporter()\n",
    "    console_processor = SimpleSpanProcessor(console_exporter)\n",
    "    \n",
    "    # Add the processor to the existing tracer provider\n",
    "    if hasattr(tracer_provider, 'add_span_processor'):\n",
    "        tracer_provider.add_span_processor(console_processor)\n",
    "        print(\"‚úÖ Console tracing enabled - traces will also print to console\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Console tracing not available with current tracer provider\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not set up console tracing: {e}\")\n",
    "    print(\"üí° This is optional - Azure Monitor tracing should still work\")\n",
    "\n",
    "# Test with console tracing\n",
    "print(\"\\nüß™ Testing with console tracing enabled...\")\n",
    "\n",
    "try:\n",
    "    client = project_client.get_openai_client(api_version=\"2024-10-21\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"What's a simple 5-minute warmup routine?\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nü§ñ Response: {response.choices[0].message.content}\")\n",
    "    print(\"\\nüîç Check console output above for detailed trace spans\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dbb932",
   "metadata": {},
   "source": [
    "# 5. Agent Tracing with Azure AI Agents SDK\n",
    "\n",
    "Following the official Microsoft documentation for tracing agents, we'll now demonstrate:\n",
    "1. **Setting up agent instrumentation** using `AIAgentsInstrumentor`\n",
    "2. Creating a **Health Resource Agent** with file search capabilities\n",
    "3. **Tracing agent operations** with proper span creation\n",
    "4. Viewing traces in the **Azure AI Foundry portal**\n",
    "\n",
    "> The agent tracing approach follows the official pattern from: https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/trace-agents-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ad934",
   "metadata": {},
   "source": [
    "## 5.1 Enable Agent Instrumentation\n",
    "\n",
    "Following Microsoft's official documentation, we need to instrument the Azure AI Agents SDK to enable tracing for agent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e09113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable agent instrumentation following Microsoft's official pattern\n",
    "from azure.ai.agents.telemetry import AIAgentsInstrumentor\n",
    "from opentelemetry import trace\n",
    "\n",
    "print(\"üîß Setting up agent instrumentation...\")\n",
    "\n",
    "# Instrument the Azure AI Agents SDK (Microsoft official pattern)\n",
    "AIAgentsInstrumentor().instrument()\n",
    "print(\"‚úÖ Azure AI Agents SDK instrumented for tracing\")\n",
    "\n",
    "# Get tracer for creating custom spans\n",
    "tracer = trace.get_tracer(__name__)\n",
    "print(\"‚úÖ Tracer ready for creating custom spans\")\n",
    "\n",
    "print(\"\\nüéØ Agent operations will now be traced and sent to Azure AI Foundry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145eb186",
   "metadata": {},
   "source": [
    "## 5.2 Create Sample Files & Vector Store\n",
    "\n",
    "We'll create dummy `.md` files about recipes/guidelines, then push them into a **vector store** so our agent can do semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f604175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_files():\n",
    "    \"\"\"Create some local .md files with sample text.\"\"\"\n",
    "    recipes_md = (\n",
    "        \"# Healthy Recipes Database\\n\\n\"\n",
    "        \"## Gluten-Free Recipes\\n\"\n",
    "        \"1. Quinoa Bowl\\n\"\n",
    "        \"   - Ingredients: quinoa, vegetables, olive oil\\n\"\n",
    "        \"   - Instructions: Cook quinoa, add vegetables\\n\\n\"\n",
    "        \"2. Rice Pasta\\n\"\n",
    "        \"   - Ingredients: rice pasta, mixed vegetables\\n\"\n",
    "        \"   - Instructions: Boil pasta, saut√© vegetables\\n\\n\"\n",
    "        \"## Diabetic-Friendly Recipes\\n\"\n",
    "        \"1. Low-Carb Stir Fry\\n\"\n",
    "        \"   - Ingredients: chicken, vegetables, tamari sauce\\n\"\n",
    "        \"   - Instructions: Cook chicken, add vegetables\\n\\n\"\n",
    "        \"## Heart-Healthy Recipes\\n\"\n",
    "        \"1. Baked Salmon\\n\"\n",
    "        \"   - Ingredients: salmon, lemon, herbs\\n\"\n",
    "        \"   - Instructions: Season salmon, bake\\n\\n\"\n",
    "        \"2. Mediterranean Bowl\\n\"\n",
    "        \"   - Ingredients: chickpeas, vegetables, tahini\\n\"\n",
    "        \"   - Instructions: Combine ingredients\\n\"\n",
    "    )\n",
    "\n",
    "    guidelines_md = (\n",
    "        \"# Dietary Guidelines\\n\\n\"\n",
    "        \"## General Guidelines\\n\"\n",
    "        \"- Eat a variety of foods\\n\"\n",
    "        \"- Control portion sizes\\n\"\n",
    "        \"- Stay hydrated\\n\\n\"\n",
    "        \"## Special Diets\\n\"\n",
    "        \"1. Gluten-Free Diet\\n\"\n",
    "        \"   - Avoid wheat, barley, rye\\n\"\n",
    "        \"   - Focus on naturally gluten-free foods\\n\\n\"\n",
    "        \"2. Diabetic Diet\\n\"\n",
    "        \"   - Monitor carbohydrate intake\\n\"\n",
    "        \"   - Choose low glycemic foods\\n\\n\"\n",
    "        \"3. Heart-Healthy Diet\\n\"\n",
    "        \"   - Limit saturated fats\\n\"\n",
    "        \"   - Choose lean proteins\\n\"\n",
    "    )\n",
    "\n",
    "    with open(\"recipes.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(recipes_md)\n",
    "    with open(\"guidelines.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(guidelines_md)\n",
    "\n",
    "    print(\"üìÑ Created sample resource files: recipes.md, guidelines.md\")\n",
    "    return [\"recipes.md\", \"guidelines.md\"]\n",
    "\n",
    "def create_vector_store(files, store_name=\"my_health_resources\"):\n",
    "    try:\n",
    "        uploaded_ids = []\n",
    "        for fp in files:\n",
    "            upl = project_client.agents.files.upload_and_poll(\n",
    "                file_path=fp,\n",
    "                purpose=\"assistants\"\n",
    "            )\n",
    "            uploaded_ids.append(upl.id)\n",
    "            print(f\"‚úÖ Uploaded: {fp} -> File ID: {upl.id}\")\n",
    "\n",
    "        # Create vector store from these file IDs\n",
    "        vs = project_client.agents.vector_stores.create_and_poll(\n",
    "            file_ids=uploaded_ids,\n",
    "            name=store_name\n",
    "        )\n",
    "        print(f\"üéâ Created vector store '{store_name}', ID: {vs.id}\")\n",
    "        return vs, uploaded_ids\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating vector store: {e}\")\n",
    "        return None, []\n",
    "\n",
    "# Create files and vector store\n",
    "sample_files = create_sample_files()\n",
    "vector_store, file_ids = None, []\n",
    "\n",
    "if sample_files:\n",
    "    vector_store, file_ids = create_vector_store(sample_files, store_name=\"health_resources_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6995a6",
   "metadata": {},
   "source": [
    "## 5.3 Create Health Resource Agent with Tracing\n",
    "\n",
    "We'll create an agent with file search capabilities. Following Microsoft's official pattern, we wrap the agent creation in a traced span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_health_agent(vs_id):\n",
    "    \"\"\"Create an agent with file search capabilities, wrapped in a traced span.\"\"\"\n",
    "    try:\n",
    "        # Wrap agent creation in a traced span (Microsoft official pattern)\n",
    "        with tracer.start_as_current_span(\"create_agent\") as span:\n",
    "            span.set_attribute(\"agent.model\", os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"))\n",
    "            span.set_attribute(\"agent.name\", \"health-search-agent\")\n",
    "            span.set_attribute(\"vector_store.id\", vs_id)\n",
    "            \n",
    "            agent = project_client.agents.create_agent(\n",
    "                model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
    "                name=\"health-search-agent\",\n",
    "                instructions=\"\"\"\n",
    "                    You are a health resource advisor with access to dietary and recipe files.\n",
    "                    You:\n",
    "                    1. Always present disclaimers (you're not a medical professional)\n",
    "                    2. Provide references to files when possible\n",
    "                    3. Focus on general nutrition or recipe tips.\n",
    "                    4. Encourage professional consultation for more detailed advice.\n",
    "                \"\"\",\n",
    "                tools=[{\"type\": \"file_search\"}]\n",
    "            )\n",
    "            \n",
    "            span.set_attribute(\"agent.id\", agent.id)\n",
    "            print(f\"üéâ Created agent '{agent.name}' with ID: {agent.id}\")\n",
    "            print(\"üìã Vector store will be attached at message level\")\n",
    "            \n",
    "            return agent\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating health agent: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create agent with tracing\n",
    "health_agent = None\n",
    "if vector_store:\n",
    "    health_agent = create_health_agent(vector_store.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ae1d7",
   "metadata": {},
   "source": [
    "## 5.4 Run Agent with Tracing\n",
    "\n",
    "Following Microsoft's official pattern from the documentation, we wrap the entire agent execution in a traced span. This ensures all agent operations are captured and sent to Azure AI Foundry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e565bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run agent with proper tracing (Microsoft official pattern)\n",
    "if health_agent and file_ids:\n",
    "    print(\"üöÄ Running agent with tracing enabled...\\n\")\n",
    "    \n",
    "    # Wrap the entire agent session in a traced span (Microsoft official pattern)\n",
    "    with tracer.start_as_current_span(\"example-tracing\") as span:\n",
    "        span.set_attribute(\"agent.id\", health_agent.id)\n",
    "        span.set_attribute(\"agent.name\", health_agent.name)\n",
    "        \n",
    "        # Create thread\n",
    "        thread = project_client.agents.threads.create()\n",
    "        span.set_attribute(\"thread.id\", thread.id)\n",
    "        print(f\"üìù Created thread: {thread.id}\\n\")\n",
    "        \n",
    "        # Ask a question - we'll attach files via tool_resources instead\n",
    "        user_question = \"Could you suggest a gluten-free lunch recipe?\"\n",
    "        print(f\"‚ùì User: {user_question}\\n\")\n",
    "        \n",
    "        # Update thread with tool resources (vector store)\n",
    "        project_client.agents.threads.update(\n",
    "            thread_id=thread.id,\n",
    "            tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}}\n",
    "        )\n",
    "        \n",
    "        # Create message without attachments - file search will use thread's tool_resources\n",
    "        message = project_client.agents.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=user_question\n",
    "        )\n",
    "        \n",
    "        # Run the agent (this is automatically traced by AIAgentsInstrumentor)\n",
    "        run = project_client.agents.runs.create_and_process(\n",
    "            thread_id=thread.id,\n",
    "            agent_id=health_agent.id\n",
    "        )\n",
    "        \n",
    "        span.set_attribute(\"run.id\", run.id)\n",
    "        span.set_attribute(\"run.status\", run.status)\n",
    "        print(f\"‚úÖ Run completed with status: {run.status}\\n\")\n",
    "        \n",
    "        # Get the agent's response\n",
    "        messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "        message_list = list(messages)\n",
    "        \n",
    "        for msg in reversed(message_list):\n",
    "            if msg.role == \"assistant\" and msg.content:\n",
    "                last_content = msg.content[-1]\n",
    "                if hasattr(last_content, \"text\"):\n",
    "                    print(f\"ü§ñ Assistant:\\n{last_content.text.value}\\n\")\n",
    "                    break\n",
    "    \n",
    "    print(\"‚úÖ Agent execution completed!\")\n",
    "    print(\"\\nüéØ Check Azure AI Foundry Tracing tab for:\")\n",
    "    print(\"   - Operation name: 'example-tracing'\")\n",
    "    print(\"   - Agent operations and tool calls\")\n",
    "    print(\"   - Message exchanges and file search results\")\n",
    "    print(\"\\n‚è±Ô∏è  Traces should appear within 2-5 minutes\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping agent execution - agent or files not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c61d8d",
   "metadata": {},
   "source": [
    "## 5.5 View Traces in Azure AI Foundry\n",
    "\n",
    "After running the agent, you can view the traces in the Azure AI Foundry portal:\n",
    "\n",
    "1. Navigate to https://ai.azure.com\n",
    "2. Open your project\n",
    "3. Click on \"Tracing\" in the left sidebar\n",
    "4. Look for traces with operation name: **\"example-tracing\"**\n",
    "\n",
    "**What you'll see in the traces:**\n",
    "- The top-level span \"example-tracing\" containing all operations\n",
    "- Agent creation span with model and configuration details\n",
    "- Thread creation and message operations\n",
    "- Agent run execution with tool calls (file search)\n",
    "- LLM calls made by the agent\n",
    "- Input/output data for each operation (if content recording is enabled)\n",
    "\n",
    "**Troubleshooting:**\n",
    "- Traces may take 2-5 minutes to appear\n",
    "- Ensure Application Insights is connected to your project\n",
    "- Check that `AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=true` is set\n",
    "- Verify the connection string was retrieved successfully earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7420c39",
   "metadata": {},
   "source": [
    "# 6. Cleanup\n",
    "If desired, we can remove the vector store, files, and agent to keep things tidy. (In a real solution, you might keep them around.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup resources to keep things tidy\n",
    "def cleanup_resources():\n",
    "    \"\"\"Clean up agent, vector store, and files created during this demo.\"\"\"\n",
    "    try:\n",
    "        print(\"üßπ Starting cleanup...\")\n",
    "        \n",
    "        # Delete vector store\n",
    "        if 'vector_store' in globals() and vector_store:\n",
    "            project_client.agents.vector_stores.delete(vector_store.id)\n",
    "            print(\"‚úÖ Deleted vector store\")\n",
    "\n",
    "        # Delete uploaded files\n",
    "        if 'file_ids' in globals() and file_ids:\n",
    "            for fid in file_ids:\n",
    "                project_client.agents.files.delete(fid)\n",
    "            print(f\"‚úÖ Deleted {len(file_ids)} uploaded files\")\n",
    "\n",
    "        # Delete agent\n",
    "        if 'health_agent' in globals() and health_agent:\n",
    "            project_client.agents.delete_agent(health_agent.id)\n",
    "            print(\"‚úÖ Deleted agent\")\n",
    "\n",
    "        # Delete local sample files\n",
    "        if 'sample_files' in globals() and sample_files:\n",
    "            for sf in sample_files:\n",
    "                if os.path.exists(sf):\n",
    "                    os.remove(sf)\n",
    "            print(f\"‚úÖ Deleted {len(sample_files)} local sample files\")\n",
    "            \n",
    "        print(\"\\nüéâ Cleanup completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during cleanup: {e}\")\n",
    "        print(\"üí° Some resources may need to be cleaned up manually in Azure AI Foundry portal\")\n",
    "\n",
    "# Uncomment the line below to run cleanup\n",
    "# cleanup_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4956d0ec",
   "metadata": {},
   "source": [
    "# üéâ Summary\n",
    "\n",
    "Congratulations! You've successfully set up **observability and tracing** for Azure AI applications!\n",
    "\n",
    "## What You Learned\n",
    "\n",
    "1. **Basic Tracing Setup**: \n",
    "   - Set environment variables for content capture\n",
    "   - Configure Azure Monitor with Application Insights connection string\n",
    "   - Instrument OpenAI SDK with `OpenAIInstrumentor()`\n",
    "\n",
    "2. **Agent Tracing**:\n",
    "   - Instrument Azure AI Agents SDK with `AIAgentsInstrumentor()`\n",
    "   - Wrap operations in custom spans for better visibility\n",
    "   - Trace agent creation, execution, and file search operations\n",
    "\n",
    "3. **View Traces**:\n",
    "   - Access traces in Azure AI Foundry portal (Tracing tab)\n",
    "   - Monitor LLM calls, agent operations, and tool usage\n",
    "   - Debug issues with detailed span attributes\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "‚úÖ **Always configure Azure Monitor first** before making API calls\n",
    "‚úÖ **Use AIAgentsInstrumentor()** for agent tracing\n",
    "‚úÖ **Wrap operations in spans** for custom tracing\n",
    "‚úÖ **Set content recording** to capture prompts/responses (be mindful of PII)\n",
    "‚úÖ **Traces appear within 2-5 minutes** in the Azure AI Foundry portal\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the **Tracing tab** in Azure AI Foundry to see your traces\n",
    "- Add custom spans to trace specific business logic\n",
    "- Use traces to debug and optimize your AI applications\n",
    "- Integrate evaluation loops with your traces\n",
    "- Set up continuous monitoring for production workloads\n",
    "\n",
    "## Official Documentation\n",
    "\n",
    "- [Trace Applications](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/trace-application)\n",
    "- [Trace Agents SDK](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/trace-agents-sdk)\n",
    "- [Azure AI Foundry Observability](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/observability)\n",
    "\n",
    "> üèãÔ∏è **Health Reminder**: The LLM's suggestions are for demonstration only. For real health decisions, consult a professional.\n",
    "\n",
    "Happy Observing & Tracing! \udfaf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "name": "Observability_and_Tracing_Comprehensive"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
